{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting weights automatically\n",
      "Setting bias automatically\n",
      "<class 'numpy.ndarray'>\n",
      "Setting weights automatically\n",
      "Setting bias automatically\n",
      "<class 'numpy.ndarray'>\n",
      "Output1\n",
      "[array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32)]\n",
      "\n",
      "Output2\n",
      "[array([[-0.13152753]], dtype=float32),\n",
      " array([[-0.13152753]], dtype=float32),\n",
      " array([[-0.13152753]], dtype=float32),\n",
      " array([[-0.13152753]], dtype=float32),\n",
      " array([[-0.13152753]], dtype=float32),\n",
      " array([[-0.13152753]], dtype=float32),\n",
      " array([[-0.13152753]], dtype=float32),\n",
      " array([[-0.13152753]], dtype=float32),\n",
      " array([[-0.13152753]], dtype=float32),\n",
      " array([[-0.13152753]], dtype=float32)]\n",
      "\n",
      "Output1.2\n",
      "[array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32),\n",
      " array([[ 0.04559202]], dtype=float32)]\n",
      "hello\n",
      "Output1.2\n",
      "<class 'numpy.ndarray'>\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "# If using seed to replicate results.\n",
    "# np.random.seed(22)\n",
    "\n",
    "dt = 0.05  # time between each time step in the simulation.\n",
    "num_inputs = 3  # Number of Values output by the simulation\n",
    "num_outputs = 1 # OpenAI env takes a single controller input, thus the controller network must output only one.\n",
    "num_nodes = num_inputs+1  # Number of nodes in the network (must be >=nump_inputs)\n",
    "num_epochs = 10\n",
    "initial_state = np.random.randn(num_nodes,1) #tf.zeros([num_nodes,1],dtype=tf.float32)\n",
    "\n",
    "\n",
    "\n",
    "# class D_RNN():\n",
    "#     def __init__(self):\n",
    "#         self.create_network()\n",
    "        \n",
    "def create_network(set_weights=None,set_bias=None):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        set_weights - the weights for the RNN dimensions of (num_nodes+num_outputs,num_nodes)\n",
    "        \n",
    "    Returns:\n",
    "        input - placeholder in the network to input values\n",
    "        output - output \n",
    "        update_state -\n",
    "    \"\"\"\n",
    "    # _______________________________________\n",
    "    #               Setting shit\n",
    "    # _______________________________________\n",
    "    # Randomly set the wieghts when initializing else set them to whats been given.\n",
    "    if (not set_weights): set_weights = np.random.randn(num_nodes+num_outputs,num_nodes)*0.1\n",
    "\n",
    "    print('Setting weights automatically')\n",
    "    # if (not set_bias):\n",
    "    print('Setting bias automatically')\n",
    "    set_bias = np.zeros([num_nodes+num_outputs,1],dtype=np.float32)\n",
    "\n",
    "\n",
    "    # _______________________________________\n",
    "    #               Variables\n",
    "    # _______________________________________\n",
    "\n",
    "    # Each input variable feeds into one node\n",
    "    _input = tf.placeholder(tf.float32,[num_inputs,1])  # Dim 1 = 1 as this is a dynamic task that only takes one input at a time\n",
    "    _input_buffer = tf.zeros([num_nodes-num_inputs,1],dtype=tf.float32)  # used so add the input to the state in one step.\n",
    "\n",
    "    # Concatenate the inputs\n",
    "    I = tf.concat([_input,_input_buffer],0)\n",
    "    print(type(set_weights))\n",
    "    # Create the weights for the RNN\n",
    "    W = tf.Variable(set_weights, dtype=tf.float32) # could be a constant...\n",
    "    b = tf.Variable(set_bias, dtype=tf.float32) # could also be a constant...\n",
    "\n",
    "    state = tf.Variable(initial_state,dtype=tf.float32)\n",
    "\n",
    "    # _______________________________________\n",
    "    #               Operations\n",
    "    # _______________________________________\n",
    "    Wx = tf.matmul(W,state)\n",
    "    Wx_b = Wx+b\n",
    "    recurrence, output = tf.split(Wx_b,[num_nodes,num_outputs],0)\n",
    "\n",
    "    output = tf.tanh(output) * 2\n",
    "\n",
    "    next_state = state + dt * (-state+tf.tanh(recurrence + I))\n",
    "\n",
    "    update_state = state.assign(next_state)\n",
    "    \n",
    "    return _input, output, W, state\n",
    "\n",
    "\n",
    "\n",
    "_input,output, weights, update_state = create_network()\n",
    "\n",
    "_input2,output2, weights2, update_state2 = create_network()\n",
    "\n",
    "print(\"Output1\")\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "#     print(I.eval(session=sess))\n",
    "\n",
    "\n",
    "    out_list = list()\n",
    "#     _in = np.random.randn(num_inputs,1)\n",
    "    _in = np.zeros([num_inputs,1],dtype=np.float32)\n",
    "    for epoch in range(num_epochs):\n",
    "        _, out = sess.run([update_state, output],feed_dict={_input:_in})\n",
    "        out_list.append(out)\n",
    "pprint(out_list)\n",
    "\n",
    "print()\n",
    "print(\"Output2\")\n",
    "with tf.Session() as sess2:\n",
    "    init2 = tf.global_variables_initializer()\n",
    "    sess2.run(init2)\n",
    "\n",
    "#     print(I.eval(session=sess))\n",
    "\n",
    "\n",
    "    out_list2 = list()\n",
    "#     _in = np.random.randn(num_inputs,1)\n",
    "    _in2 = np.zeros([num_inputs,1],dtype=np.float32)\n",
    "    for epoch in range(num_epochs):\n",
    "        _, out2 = sess2.run([update_state2, output2],feed_dict={_input2:_in2})\n",
    "        out_list2.append(out2)\n",
    "        \n",
    "pprint(out_list2)\n",
    "\n",
    "print()\n",
    "print(\"Output1.2\")\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "#     print(I.eval(session=sess))\n",
    "\n",
    "\n",
    "    out_list = list()\n",
    "#     _in = np.random.randn(num_inputs,1)\n",
    "    _in = np.zeros([num_inputs,1],dtype=np.float32)\n",
    "    for epoch in range(num_epochs):\n",
    "        _, out = sess.run([update_state, output],feed_dict={_input:_in})\n",
    "        out_list.append(out)\n",
    "        \n",
    "\n",
    "pprint(out_list)\n",
    "print('hello')\n",
    "# pprint(out_list2)\n",
    "\n",
    "print(\"Output1.2\")\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "#     print(I.eval(session=sess))\n",
    "\n",
    "\n",
    "    out_list = list()\n",
    "#     _in = np.random.randn(num_inputs,1)\n",
    "    _in = np.zeros([num_inputs,1],dtype=np.float32)\n",
    "    for epoch in range(num_epochs):\n",
    "        _, out = sess.run([update_state, output],feed_dict={_input:_in})\n",
    "        out_list.append(out)\n",
    "        \n",
    "\n",
    "pprint(type(out))\n",
    "print('hello')\n",
    "# pprint(out_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update wieghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "(5, 4)\n",
      "[[ 0.6482929   0.73822057  0.32637706  0.8568725 ]\n",
      " [ 0.22045712  0.70231336  0.80156964  0.62236881]\n",
      " [ 0.25379252  0.11639043  0.62406945  0.30842981]\n",
      " [ 0.5354023   0.03419872  0.97649145  0.69419634]\n",
      " [ 0.6882661   0.2703771   0.43076929  0.22229286]]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(weights.shape)\n",
    "print(np.random.rand(5,4).shape)\n",
    "# with tf.Session() as sess:\n",
    "#     weights.eval()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    _ = weights.assign(np.random.rand(5,4))\n",
    "    sess.run(_)\n",
    "    x = weights.eval()\n",
    "    print((weights.eval()))\n",
    "#     print(I.eval(session=sess))\n",
    "\n",
    "\n",
    "#     out_list = list()\n",
    "# #     _in = np.random.randn(num_inputs,1)\n",
    "#     _in = np.zeros([num_inputs,1],dtype=np.float32)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         _, out = sess.run([update_state, output],feed_dict={_input:_in})\n",
    "#         out_list.append(out)\n",
    "        \n",
    "\n",
    "# pprint(out_list)\n",
    "print('hello')\n",
    "# pprint(out_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6482929   0.73822057  0.32637706  0.8568725   0.22045712  0.70231336\n",
      "  0.80156964  0.62236881  0.25379252  0.11639043  0.62406945  0.30842981\n",
      "  0.5354023   0.03419872  0.97649145  0.69419634  0.6882661   0.2703771\n",
      "  0.43076929  0.22229286]\n",
      "[[ 0.6482929   0.73822057  0.32637706  0.8568725 ]\n",
      " [ 0.22045712  0.70231336  0.80156964  0.62236881]\n",
      " [ 0.25379252  0.11639043  0.62406945  0.30842981]\n",
      " [ 0.5354023   0.03419872  0.97649145  0.69419634]\n",
      " [ 0.6882661   0.2703771   0.43076929  0.22229286]]\n"
     ]
    }
   ],
   "source": [
    "y = x.flatten()\n",
    "print(y)\n",
    "z = y.reshape(5,4)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(np.array([0,0]), dtype=tf.float32) # could be a constant..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randn() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-3a2417debe27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: randn() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "x = (np.ndarray(20,dtype=np.float32,buffer=np.random.randn(30,dtype=np.float64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144809743703127563320034328576\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-7740\n",
      "-1\n",
      "0\n",
      "-1\n",
      "15154207694765582530415231264266125312\n",
      "-1\n",
      "0\n",
      "-1\n",
      "2004269268992\n",
      "-1\n",
      "-159798368665600\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "[  1.44809744e+29  -1.53880596e+00  -1.77189452e-03  -1.80627823e+00\n",
      "  -7.74072754e+03  -1.82374251e+00  -1.05827713e-27  -1.78213370e+00\n",
      "   1.51542077e+37  -1.65595436e+00  -9.76384407e-16  -1.94887066e+00\n",
      "   2.00426927e+12  -1.88745439e+00  -1.59798369e+14  -1.82660890e+00\n",
      "   8.64459241e-28  -1.88203919e+00   5.80202697e-38  -1.75078058e+00]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x)):\n",
    "    print(int(x[i]))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.90465512  0.26513949  0.10382357  0.22045395  0.66880977  0.69013287\n",
      "  0.26185601  0.14889424  0.68326228  0.93419833  0.63279823  0.41949724\n",
      "  0.03218025  0.40777749  0.01496023  0.50798798  0.83998934  0.236279\n",
      "  0.8988143   0.7319778 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.ndarray(shape=(20,),dtype=np.float64,buffer=np.random.rand(20),order='C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97750711  0.06729285  0.216847    0.97305167  0.96610582  0.88966554\n",
      "  0.68340278  0.0358297   0.82549763  0.10041883  0.28043225  0.87453747\n",
      "  0.31804729  0.01632436  0.73075151  0.8514083   0.15043195  0.05581134\n",
      "  0.04836659  0.47963995]\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "x = np.ndarray(shape=(20),buffer=np.random.rand(20)).astype(np.float32)\n",
    "print(x)\n",
    "y = x.astype(np.float32)\n",
    "print(type(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ndarray(shape=20,buffer=x,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(20).astype(np.float32)\n",
    "print(type(x))\n",
    "y = x.astype(np.float32)\n",
    "print(type(y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pendulum_v0_py3]",
   "language": "python",
   "name": "conda-env-pendulum_v0_py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
